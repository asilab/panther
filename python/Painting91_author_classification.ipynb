{
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "**Save features from VGG16 Conv layer**\n",
    "\n",
    "Using first convolutional layer from convolutional block 5\\\n",
    "512 feature maps with a size of 14x14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model\n",
    "from keras.applications import VGG16\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "def save_image_features():\n",
    "    # build model from VGG16 network, only up to the first convolutional layer from convolutional block 5\n",
    "    base_model = VGG16(include_top=False, weights='imagenet')\n",
    "    base_model.trainable = False\n",
    "    model = Model(inputs=base_model.input, outputs=base_model.get_layer('block5_conv1').output)\n",
    "#    model.summary()\n",
    "\n",
    "    # image generator from directory\n",
    "    datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "    generator = datagen.flow_from_directory(\n",
    "        '../Labels_Author/Train',\n",
    "        target_size=(224, 224),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False)\n",
    "    \n",
    "    # obtain covolutional features\n",
    "    features_train = model.predict(generator)\n",
    "    \n",
    "    # save training features\n",
    "    np.save(open('../data/vgg16conv51_features_author_train.npy', 'wb'),\n",
    "            features_train)\n",
    "\n",
    "    # save training labels\n",
    "    labels = [int(filepath.split('/')[-2]) for filepath in generator.filepaths]\n",
    "    np.save(open('../data/labels_author_train.npy', 'wb'), labels)\n",
    "    np.save(open('../data/files_author_train.npy', 'wb'), generator.filepaths)\n",
    "    \n",
    "\n",
    "    generator = datagen.flow_from_directory(\n",
    "        '../Labels_Author/Test',\n",
    "        target_size=(224, 224),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False)\n",
    "    \n",
    "    # obtain covolutional features\n",
    "    features_test = model.predict(generator)\n",
    "    \n",
    "    # save test features\n",
    "    np.save(open('../data/vgg16conv51_features_author_test.npy', 'wb'),\n",
    "            features_test)\n",
    "\n",
    "    # save test labels\n",
    "    labels = [int(filepath.split('/')[-2]) for filepath in generator.filepaths]\n",
    "    np.save(open('../data/labels_author_test.npy', 'wb'), labels)\n",
    "    np.save(open('../data/files_author_test.npy', 'wb'), generator.filepaths)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_image_features()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "**Generate Gram matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import decomposition\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def save_gram_features(scale=False):\n",
    "\n",
    "    # Load and reshape training data\n",
    "    # Original shape (, 14, 14, 512)\n",
    "    # Resulting shape after vectorizing feature maps (, 196, 512)\n",
    "    train_data = np.load(open('../data/vgg16conv51_features_author_train.npy', 'rb'))\n",
    "    train_data = train_data.reshape(train_data.shape[0], -1, 512)\n",
    "    test_data = np.load(open('../data/vgg16conv51_features_author_test.npy', 'rb'))\n",
    "    test_data = test_data.reshape(test_data.shape[0], -1, 512)\n",
    "    #print(train_data.shape)\n",
    "\n",
    "    # Calculate Gram matrix values as dot product of feature map vectors: 196x512 -> 512x512\n",
    "    # Vectorize upper diagonal (of symmetrical matrix) to vector of length 512*513/2 = 131328 \n",
    "\n",
    "    # should be the same, except for the selection of upper diagonal, as:\n",
    "    #G_train = np.matmul(np.transpose(train_data, (0, 2, 1)), train_data)\n",
    "    #G_train = G_train.reshape(G_train.shape[0], -1)\n",
    "\n",
    "    G_train = np.zeros((train_data.shape[0], 131328))\n",
    "    for k in range(train_data.shape[0]):\n",
    "        g = train_data[k,].T.dot(train_data[k,])\n",
    "        G_train[k,] = g[np.triu_indices_from(g)]\n",
    "\n",
    "    G_test = np.zeros((test_data.shape[0], 131328))\n",
    "    for k in range(test_data.shape[0]):\n",
    "        g = test_data[k,].T.dot(test_data[k,])\n",
    "        G_test[k,] = g[np.triu_indices_from(g)]\n",
    "\n",
    "    #print(G_train.shape)\n",
    "\n",
    "    # Reduce dimensions by PCA\n",
    "    if scale:\n",
    "        scaler = StandardScaler().fit(G_train)\n",
    "        G_train = scaler.transform(G_train)\n",
    "        G_test = scaler.transform(G_test)\n",
    "\n",
    "    pca = decomposition.PCA(n_components=2048).fit(G_train)\n",
    "    x_train = pca.transform(G_train)\n",
    "    x_test = pca.transform(G_test)\n",
    "\n",
    "    #print(x_train.shape)\n",
    "    \n",
    "    np.save(open('../data/gram_features_author_train.npy', 'wb'), x_train)\n",
    "    np.save(open('../data/gram_features_author_test.npy', 'wb'), x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_gram_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "\n",
    "\n",
    "x_train = np.load(open('../data/gram_features_author_train.npy', 'rb'))\n",
    "x_test = np.load(open('../data/gram_features_author_test.npy', 'rb'))\n",
    "\n",
    "train_labels = np.load(open('../data/labels_author_train.npy', 'rb'))\n",
    "test_labels = np.load(open('../data/labels_author_test.npy', 'rb'))\n",
    "\n",
    "\n",
    "clf = svm.SVC(kernel='linear', C=1)\n",
    "#clf = RandomForestClassifier(n_estimators=10)\n",
    "#clf = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0)\n",
    "\n",
    "data = np.concatenate((x_train, x_test), axis=0)\n",
    "print(\"5-fold CV accuracy using all data (%i instances)\" %(len(data)))\n",
    "labels = np.concatenate((train_labels, test_labels), axis=0)\n",
    "k_fold = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "print(cross_val_score(clf, data, labels, cv=k_fold, n_jobs=-1))\n",
    "\n",
    "\n",
    "print(\"\\nAccuracy on test set\")\n",
    "clf.fit(x_train, train_labels)\n",
    "print(clf.score(x_test, test_labels))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "**Prepare combined data representations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def combined_features(normalized=False):\n",
    "\n",
    "    x_train = np.load(open('../data/gram_features_author_train.npy', 'rb'))\n",
    "    x_test = np.load(open('../data/gram_features_author_test.npy', 'rb'))\n",
    "    train_files = np.load(open('../data/files_author_train.npy', 'rb'))\n",
    "    test_files = np.load(open('../data/files_author_test.npy', 'rb'))\n",
    "\n",
    "    if normalized:\n",
    "        nc_data_tmp = np.load(\"../data/nc_data_normalized.npy\", allow_pickle=True).item()\n",
    "    else:\n",
    "        nc_data_tmp = np.load(\"../data/nc_data.npy\", allow_pickle=True).item()\n",
    "        \n",
    "    nc_data = dict()\n",
    "    nc_data_64 = dict()\n",
    "    nc_data_1024 = dict()\n",
    "    hdc_data = dict()\n",
    "    alpha_data = dict()\n",
    "    for i, painting in enumerate(nc_data_tmp['painting']):\n",
    "        painting = painting.split('.')[0]\n",
    "        nc_data[painting] = nc_data_tmp['nc_256'][i]\n",
    "        nc_data_64[painting] = nc_data_tmp['nc_64'][i]\n",
    "        nc_data_1024[painting] = nc_data_tmp['nc_1024'][i]\n",
    "        hdc_data[painting] = nc_data_tmp['hdc'][i]\n",
    "        alpha_data[painting] = nc_data_tmp['alpha'][i]\n",
    "\n",
    "    x_train_nc_64 = np.zeros((train_files.shape[0], 64))\n",
    "    x_train_nc_1024 = np.zeros((train_files.shape[0], 1024))\n",
    "    x_train_nc_256 = np.zeros((train_files.shape[0], 256))\n",
    "    x_train_hdc = np.zeros((train_files.shape[0], 89))\n",
    "    x_train_alpha = np.zeros((train_files.shape[0], 1))\n",
    "    \n",
    "    for i, painting in enumerate(train_files):\n",
    "        painting = painting.split('/')[-1].split('.')[0]\n",
    "        x_train_nc_256[i, ] = nc_data[painting]\n",
    "        x_train_nc_1024[i, ] = nc_data_1024[painting]\n",
    "        x_train_nc_64[i, ] = nc_data_64[painting]\n",
    "        x_train_hdc[i, ] = hdc_data[painting]\n",
    "        x_train_alpha[i, ] = alpha_data[painting]\n",
    "\n",
    "    x_test_nc_64 = np.zeros((test_files.shape[0], 64))\n",
    "    x_test_nc_1024 = np.zeros((test_files.shape[0], 1024))\n",
    "    x_test_nc_256 = np.zeros((test_files.shape[0], 256))\n",
    "    x_test_hdc = np.zeros((test_files.shape[0], 89))\n",
    "    x_test_alpha = np.zeros((test_files.shape[0], 1))\n",
    "    for i, painting in enumerate(test_files):\n",
    "        painting = painting.split('/')[-1].split('.')[0]\n",
    "        x_test_nc_64[i, ] = nc_data_64[painting] \n",
    "        x_test_nc_256[i, ] = nc_data[painting]\n",
    "        x_test_nc_1024[i, ] = nc_data_1024[painting]\n",
    "        x_test_hdc[i, ] = hdc_data[painting]\n",
    "        x_test_alpha[i, ] = alpha_data[painting]\n",
    "\n",
    "    X_train = np.concatenate((x_train, x_train_nc_256, x_train_nc_1024, x_train_hdc, x_train_alpha, x_train_nc_64), axis=1)\n",
    "    X_test = np.concatenate((x_test, x_test_nc_256, x_test_nc_1024, x_test_hdc, x_test_alpha, x_test_nc_64), axis=1)\n",
    "\n",
    "    return X_train, X_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "**Using ColumnTranformer to combine multiple representations (feature sets)**\n",
    "\\\n",
    "Need to define function \"combined_features\" by running the cell above \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "def selector(X):\n",
    "    return X\n",
    "\n",
    "ct1 = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('gram', FunctionTransformer(selector), slice(0, 2048)),\n",
    "    ],\n",
    ")\n",
    "\n",
    "ct2 = ColumnTransformer(\n",
    "    transformers=[\n",
    "        \n",
    "        ('nc256', FunctionTransformer(selector), slice(2048, 2304)),\n",
    "        ('nc1024', FunctionTransformer(selector), slice(2304, 3328)),        \n",
    "        ('hdc', MaxAbsScaler(), slice(3328, 3417)),\n",
    "        ('alpha', FunctionTransformer(selector), [3417]),\n",
    "        ('nc64', FunctionTransformer(selector), slice(3418, 3482)),\n",
    "    ],\n",
    "    transformer_weights={\n",
    "        'nc_64':1.0,'nc_256':1.0, 'nc1024': 1.0, 'hdc': 1.0, 'alpha': 1.0},\n",
    ")\n",
    "\n",
    "\n",
    "ct3 = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('nc256', FunctionTransformer(selector), slice(2048, 2304)),\n",
    "    ],\n",
    ")\n",
    "\n",
    "clf1 = SVC(kernel='linear', gamma='auto', probability=True)\n",
    "pipe1 = Pipeline(\n",
    "    steps=[\n",
    "        ('ct1', ct1),\n",
    "        ('clf1', clf1),\n",
    "    ],\n",
    ")\n",
    "\n",
    "\n",
    "clf2 = XGBClassifier(max_depth=3, learning_rate=0.1, n_estimators=160)\n",
    "pipe2 = Pipeline(\n",
    "    steps=[\n",
    "        ('ct2', ct2),\n",
    "        ('clf2', clf2),\n",
    "    ],\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "clf3 = XGBClassifier(max_depth=3, learning_rate=0.16, n_estimators=445)\n",
    "pipe3 = Pipeline(\n",
    "    steps=[\n",
    "        ('ct3', ct3),\n",
    "        ('clf3', clf3),\n",
    "    ],\n",
    ")\n",
    "\n",
    "\n",
    "clf_gram_nc = VotingClassifier(estimators=[(\"gram\", pipe1), (\"nc_256\", pipe3)], voting='soft', weights=[7,1])\n",
    "\n",
    "clf = VotingClassifier(estimators=[(\"gram\", pipe1), (\"all_features\", pipe2)], voting='soft', weights=[7,1]) #BEST\n",
    "\n",
    "X_train, X_test = combined_features(normalized=False)\n",
    "\n",
    "\n",
    "train_labels = np.load(open('../data/labels_author_train.npy', 'rb'))\n",
    "test_labels = np.load(open('../data/labels_author_test.npy', 'rb'))\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\nAccuracy on test set\")\n",
    "\n",
    "print(\"\\nUsing Gram features\")\n",
    "pipe1.fit(X_train, train_labels)\n",
    "print(pipe1.score(X_test, test_labels))\n",
    "\n",
    "print(\"\\nUsing Gram + nc features nc_256\")\n",
    "clf_gram_nc.fit(X_train, train_labels)\n",
    "print(clf_gram_nc.score(X_test, test_labels))\n",
    "\n",
    "print(\"\\nUsing Gram features and NC+HDC, with Voting\")\n",
    "clf.fit(X_train, train_labels)\n",
    "print(clf.score(X_test, test_labels))\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Untitled1.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}